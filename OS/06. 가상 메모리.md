# Chapter 14 : 가상 메모리

## 연속 메모리 할당

- 지금까지는 메모리 내에 프로세스가 연속적으로 배치되는 상황을 가정했고, 이 방식은 **연속 메모리 할당** 방식이라고 한다.

### 스와핑

- 메모리에 적재된 프로세스들 중에서는 현재 실행되지 않는 프로세스가 있을 수 있다.
  - 입출력 작업으로 대기 상태가 되었거나, 오랫동안 사용되지 않은 프로세스들.
- 이런 프로세스들을 임시로 보조기억장치 일부 영역으로 쫓아내고, 그 빈 자리를 다른 프로세스로 채워 실행하는 방식을 **스와핑**이라고 한다.
- 이 때 프로세스들이 쫒겨나는 보조기억장치 일부 영역을 **스왑 영역**이라고 한다.
- 현재 실행되지 않은 프로세스가 메모리에서 스왑 영역으로 옮겨지는 것을 **스왑 아웃**, 반대로 스왑 영역에 있던 프로세스가 다시 메모리로 옮겨오는 것을 **스왑 인**이라고 한다.
- 스왑 아웃된 프로세스가 다시 스왑 인 될때는 스왑 아웃되기 전의 물리 주소와 다른 주소에 적재될 수 있다.
- 스와핑을 이용하면 프로세스들이 요구하는 메모리 주소 공간의 크기가 실제 메모리 크기보다 큰 경우에도 프로세스들을 동시 실행할 수 있다.
  - 넘치는 부분을 스와핑하며 실행할 수 있기 때문이다.
- 유닉스, 리눅스, 맥에선 DOS 명령어를 통해 스왑 영역의 크기를 확인하고, 크기를 설정할 수 있다.

### 메모리 할당

- 프로세스는 메모리 내의 빈 공간에 적재되는데, 빈 공간이 여러 개 있을 경우 할당 방식이 다르다.
- 여기엔 대표적으로 최초 적합, 최적 적합, 최악 적합 세 가지 방식이 존재한다.
- **최초 적합**
  - 운영체제가 메모리 내의 빈 공간을 순서대로 검색하다가 적재할 수 있는 **공간이 발견되면** 그 공간에 프로세스를 배치하는 방식이다.
  - 검색을 최소화하고 결과적으로 빠른 할당이 가능하다.
  - 빈 공간이 비교적 큰 공간이더라도 일단 적재하게 된다.
- **최적 적합**
  - 운영체제가 빈 공간을 모두 검색해 본 후, 프로세스가 적재될 수 있는 공간 중 가장 **작은** 공간에 프로세스를 배치하는 방식이다.
  - 가장 크기에 알맞는 메모리에 적재 가능하지만, 메모리를 모두 검색하게 된다.
- **최악 적합**
  - 운영체제가 빈 공간을 모두 검색해 본 후, 프로세스가 적재될 수 있는 공간 중 가장 **큰** 공간에 프로세스를 배치하는 방식이다.

### 외부 단편화

- 프로세스를 메모리에 연속으로 배치하는 것은 언뜻 당연해보이나, 사실 이는 메모리를 효율적으로 사용하는 방법은 아니다.
- 왜냐하면, 연속 메모리 할당은 **외부 단편화**(External Fragmentation)라는 문제를 내포하고 있기 때문이다.
- 만약 프로세스 크기가 순서대로 크고 - 작고 - 크고 - 작은 것들이 연속으로 할당되었다고 치자.
  - 이후 작은 프로세스 두 개가 실행이 끝나 메모리를 떠나면, 작은 공간이 두 개 비게 된다.
  - 그 때 남아있는 총 공간이 50MB라고 해도, 50MB짜리 프로세스를 적재할 수 없게 된다.
  - 빈 공간이 큰 프로세스를 적재하기 어려운 상황을 초래하고, 메모리 낭비로 이어지는 현상을 외부 단편화라고 한다.
  - 스와핑을 통해 프로세스가 스왑 아웃되고, 더 작은 프로세스가 스왑 인 될때도 외부 단편화가 발생한다.
- 실제로는 외부 단편화가 많이 일어나면 낭비되는 공간이 더더욱 커진다.
- 외부 단편화를  해결할 수 있는 대표적인 방안으로 메모리를 **압축**하는 방법이 있다.
- 이는 **메모리 조각 모음**이라고도 부른다.
- 여기저기 흩어진 빈 공간들을 하나로 모으는 방식으로, 프로세스를 적당히 재배치해 큰 빈 공간을 만드는 방법이다.
- 압축 방식엔 여러 단점이 있는데, 공간들을 하나로 모으는 동안 시스템은 하던 일을 중지하고 내용을 옮기며 오버헤드를 야기한다.
- 어떤 프로세스를 어떻게 움직여야 오버헤드를 최소화할 수 있는지 명확한 방법을 결정하기 어렵다.
- 오늘날 외부 단편화를 없애는 또 다른 해결 방안이 등장했는데, 이가 가상 메모리 기법, 그 중에서도 페이징 기법이다.

## 페이징을 통한 가상 메모리 관리

- 메모리에 프로세스를 연속으로 할당하는 방식은 두 가지 단점이 있다.
  1. 외부 단편화가 야기된다.
  2. 물리 메모리보다 더 크기가 큰 프로세스를 실행할 수 없다.
- **가상 메모리**(Virtual Memory)는 실행하고자 하는 프로그램을 일부만 메모리에 적재하여 실제 물리 메모리 크기보다 더 큰 프로세스를 실행할 수 있게 하는 기술이다.
- 이를 가능케 하는 가상 메모리 관리 기법은 크게 **페이징**과 **세그멘테이션**이 있다.
- 현대 대부분의 운영체제가 페이징 기법을 다루며, 이는 외부 단편화도 해결한다.

### 페이징이란

- 메모리와 프로세스를 일정한 단위로 자르고, 이를 메모리에 불연속적으로 할당할 수 있다면 외부 단편화는 발생하지 않는다. 이 기법이 **페이징**(Paging)이다.
- 페이징은 프로세스의 논리 주소 공간을 **페이지**라는 일정한 단위로 자르고, 메모리 물리 주소 공간을 **프레임**이라는 페이지와 동일한 크기의 일정한 단위로 자른 뒤 페이지를 프레임에 할당하는 가상 메모리 관리 기법이다.
- 페이징에서 스와핑을 사용할 수 있는데, 이 경우 프로세스 전체가 스왑 아웃/스왑 인 되는 것이 아닌 **페이지 단위**로 스왑 아웃/스왑 인 된다.
- 페이징 시스템에서의 스왑 아웃을 **페이지 아웃**, 스왑 인은 **페이지 인**이라고도 한다.
- 이는 다르게 말하면 프로세스를 실행하기 위해 그 전체가 메모리에 적재될 필요는 없다는 것이다.
- 이 방식을 통해 물리 메모리보다 더 큰 프로세스를 실행할 수 있게 된다.

### 페이지 테이블

- 문제가 있다면, 프로세스가 메모리에 불연속적으로 배치되어 있다면 CPU 입장에선 이를 순차적으로 실행할 수가 없다.
- 프로세스를 이루는 페이지가 어느 프레임에 적재되어 있는지 CPU가 모두 알고 있기 어렵기 때문이다.
- 즉, CPU 입장에선 '다음 실행할 명령어 위치'를 찾기가 어려워진다.
- 이를 해결하기 위해 페이징 시스템은, 비록 물리 주소에 불연속적으로 배치되더라도 논리 주소만큼은 연속적으로 배치되도록 **페이지 테이블**을 이용한다.
- 페이지 테이블은 페이지 번호와 프레임 번호를 짝지어주는 이정표이다.
- CPU가 페이지 테이블에 적힌 페이지 번호만 보아도, 해당 페이지가 적재된 프레임을 찾을 수 있게 된다.
- 물리 주소에 프로세스가 어지럽게 정리되어 있어도, 페이지 테이블에서의 논리 주소는 페이지 번호 0번부터 쭉 정리되어 있다.
- 페이징은 외부 단편화 문제를 해결할 수 있지만, **내부 단편화** 문제를 야기할 수 있다.
  - 모든 프로세스가 페이지 크기에 딱 맞게 잘리는 것은 아니다.
  - 가령 페이지 단위가 10KB인데, 프로세스 크기가 108KB라면 2KB 만큼의 크기가 남는다. 이런 메모리 낭비를 내부 단편화라고 한다.
  - 내부 단편화는 하나의 페이지 크기보다 작은 크기로 발생하기 때문에, 페이지 크기를 작게 하면 그만큼 낭비되는 크기는 작아지겠지만 페이지 테이블의 크기도 커져 페이지 테이블이 차지하는 공간이 낭비된다.
  - 기본적으로 설정된 페이지보다 큰 페이지를 대형 페이지라고 한다.
- 프로세스마다 각자의 프로세스 테이블을 하나씩 가지고 있고, 각 프로세스의 페이지 테이블은 메모리에 적재되어 있다.
- CPU 내의 **페이지 테이블 베이스 레지스터**(PTBR)는 각 프로세스의 페이지 테이블이 적재된 주소를 가리키고 있다.
  - 이러한 각 프로세스들의 페이지 테이블 정보들은 각 프로세스의 PCB에 기록된다. 또한 프로세스의 문맥 교환이 일어날 때 다른 레지스터와 마찬가지로 함께 변경된다.
- 그러나 이렇게 페이지 테이블을 두면, 메모리 접근 시간이 두 배로 늘어나게 된다.
  - 페이지 테이블에 접근하는 것, 프레임에 접근하는 것으로 두 번 접근이 필요하기 때문이다.
- 이와 같은 문제를 해결하기 위해 CPU 곁(보통 MMU 내)에 **TLB**(Translation Lookaside Buffer)라는 페이지 테이블의 캐시 메모리를 둔다.
- TLB는 페이지 테이블의 캐시여서 테이블의 일부 내용을 저장하고, 참조 지역성에 의거해 주로 최근에 사용된 페이지 위주로 가져와 저장한다.
- CPU가 발생한 논리 주소에 대한 페이지 번호가 TLB에 있을 경우, 이를 **TLB 히트**라고 한다.
- 이 경우 페이지가 적재된 프레임을 알기 위해 메모리에 접근할 필요 없이 바로 캐시를 보게
-  된다.
- 만약 페이지 번호가 TLB에 없다면 메모리에 접근할 수밖에 없고, 이를 **TLB 미스**라고 한다.

### 페이징에서의 주소 변환

- 하나의 페이지나 프레임은 여러 주소를 포괄하고 있다. 그렇기에 특정 주소에 접근하려면 아래와 같은 두 가지 정보가 필요하다.
  - 어떤 페이지 혹은 프레임에 접근하고 싶은지
  - 접근하려는 주소가 그 페이지 혹은 프레임으로부터 얼마나 떨어져 있는지
- 그렇기에 페이징 시스템에서는 모든 논리 주소가 기본적으로 **페이지 번호**와 **변위**로 이루어져 있다.
- CPU가 32비트 주소를 내보냈다면 페이지 번호는 N비트, 변위는 32-N비트이다.
- 페이지 번호는 말 그대로 접근하고자 하는 페이지 번호이다. 페이지 번호를 알면 페이지 테이블을 통해 그 페이지가 어떤 프레임에 할당되어있는지를 알 수 있다.
- 변위는 접근하려는 주소가 프레임의 시작 번지로부터 얼마나 떨어져있는지를 알기 위한 정보이다.
- 즉 논리 주소는 <페이지 번호, 변위>는 페이지 테이블을 통해 물리 주소 <프레임 번호, 변위>로 변환된다.

### 페이지 테이블 엔트리

- 페이지 테이블의 각 엔트리, 즉 행들은 **페이지 테이블 엔트리**(PTE)라고 한다.
- 페이지 테이블 엔트리엔 페이지 번호, 프레임 번호 뿐만이 아니라 유효 비트, 보호 비트, 참조 비트, 수정 비트 등의 내용들도 담겨있다.
- **유효 비트**
  - 유효 비트는 현재 해당 페이지에 접근 가능한지 여부를 알려준다.
  - 프레임 번호 다음으로 중요한 정보라고도 할 수 있다.
  - 프로세스를 이루는 페이지들이 모두 스와핑이 가능한데, 대체로 메모리에 적재된 페이지보다 보조기억장치(스왑 영역)에 저장된 페이지가 더 많다.
  - 따라서 유효 비트는 해당 페이지가 메모리에 적재되어 있다면 1, 메모리에 적재되어 있지 않다면 0이 된다.
  - 만일 CPU가 유효 비트가 0인 페이지에 접근하려 한다면 **페이지 폴트**라는 예외가 발생한다. CPU가 페이지 폴트를 처리하는 과정은 하드웨어 인터럽트 처리 과정과 유사하다.
    1. CPU는 기존 작업 내역을 백업한다.
    2. 페이지 폴트 처리 루틴을 실행한다.
    3. 페이지 처리 루틴은 원하는 페이지를 메모리로 가져온 뒤, 유효 비트를 1로 변경한다.
    4. 페이지 폴트를 처리했다면 이제 CPU는 해당 페이지에 접근할 수 있다.
- **보호 비트**
  - 보호 비트는 페이지 보호 기능을 위해 존재하는 비트이다.
  - 해당 페이지가 읽고 쓰기가 모두 가능한지, 읽기만 가능한지 나타낸다.
  - 페이지를 읽기만 할 수 있다면 0, 읽고 쓸 수 있다면 1이다.
  - 프로세스의 코드 영역은 읽기 전용 영역이므로, 이런 읽기 전용 페이지에 쓰기를 시도하면 운영체제가 이를 막아준다.
  - 세 개의 비트를 써서 조금 더 구체적으로 구현할 수 있는데, 읽기, 쓰기, 실행하기(rwx)를 각각 하나씩 비트를 둬서 권한을 나타낼 수 있다.
  - 이 경우 가능한 부분만 1이다.
- **참조 비트**
  - 참조 비트는 CPU가 해당 페이지에 접근한 적이 있는지 여부를 나타낸다.
  - 적재 이후 CPU가 읽고 쓴 페이지는 참조 비트가 1이고, 아닌 경우 0이다.
- **수정 비트**
  - 수정 비트는 해당 페이지에 데이터를 쓴 적이 있는지, 수정 여부를 알려준다.
  - **더티 비트**라고도 부르며, 이 비트가 1이면 변경된 적이 있는 페이지이다.
  - 수정 비트는 페이지가 메모리에서 사라질 때, 보조기억장치에 쓰기 작업을 해야 하는지, 할 필요가 없는지를 판단하기 위해 존재한다. 즉, 갱신된 적이 있으면 저장을 하기 위해 쓰인다.
  - 수정된 적이 있는 페이지가 스왑 아웃될 경우, 보조기억장치에 기록하는 작업을 하기 위해서이다.

### 쓰기 시 복사

- 페이징 기법은 외부 단편화 해결 뿐만 아니라 다양한 이점이 있는데, 대표적인 것이 프로세스 간에 페이지를 공유할 수 있다는 점이다.
- 그 사례로는 공유 라이브러리 등 다양하지만, 대표적인 예시로 **쓰기 시 복사**가 있다.
- 기존에 있던 프로세스 간에 기본적으로 자원을 공유하지 않는다는 전통때문에, 자식 프로세스를 생성하면 부모 프로세스를 모두 복사하고 코드 및 데이터 영역을 부모 프로세스와 전혀 다른 메모리 공간에 새로 할당하느라 시간이 많이 걸리며 메모리 낭비를 야기했다.
- 반면 쓰기 시 복사는 부모 프로세스와 동일한 자식 프로세스 생성 시, 자식 프로세스가 부모 프로세스와 동일한 프레임을 가리킨다. 굳이 복사하지 않고, 기존 부모 프로세스의 자원을 그대로 공유하는 것이다.
- 그러다가 부모나 자식 프로세스 둘 중 하나가 페이지에 쓰기 작업을 하면 그 순간 해당 페이지만 별도의 공간으로 복제된다.

### 계층적 페이징

- 페이지 테이블의 크기는 생각보다 커서, 프로세스를 이루는 모든 페이지 테이블을 페이지 테이블 엔트리를 전부 메모리에 두는 것은 큰 메모리 낭비이다.
- 이에 프로세스를 이루는 모든 페이지 테이블 엔트리를 항상 메모리에 유지하지 않아도 되는 방법이 등장했고, 이것이 **계층적 페이징**이다.
- 계층적 페이징은 페이지 테이블을 페이징하여, 여러 단계의 페이지를 두는 방식이다.
- 여러 단계의 페이지를 둔다는 점에서 **다단계 페이지 테이블**이라고도 부른다.
- 하나의 긴 페이지를 여러개로 나눈 뒤, 새로은 페이지 테이블을 하나 더 만들어(Outer 페이지 테이블) 나눈 페이지들의 주소를 적어두는 방식이다.
- 이렇게 되면 페이지 테이블 중 몇 개는 보조기억장치에 있어도 무방하며, 추후 해당 페이지 테이블을 참조해야 할 때 메모리에 적재하면 그만이다.
- 다만 Outer 페이지 테이블은 항상 메모리에 유지되어야 한다.
- 단 이 경우 CPU가 발생하는 논리 주소도 달라지는데, 기존에는 변위와 페이지 번호로 이루어져 있었다면 이젠 바깥쪽 페이지 번호, 안쪽 페이지 번호, 변위가 필요해진다.
- 바깥 페이지 테이블이 Outer 페이지 테이블의 주소를 가리키고, 안쪽 페이지 번호가 해당 페이지 테이블 안에서의 페이지 번호를 가리킨다.
- 이렇게 두 개의 계층 뿐만 아니라, 그 계층은 세 개, 네 개, 그 이상이 될 수도 있다. 단, 페이지 테이블의 계층이 늘어날 수록 페이지 폴트가 발생했을 때 메모리 참조 횟수가 많아져 계층이 많다고 해서 반드시 좋은것은 아니다.

## 페이지 교체와 프레임 할당

- 가상 메모리가 있어도 물리 메모리의 크기는 한정되어 있어, 운영체제는 합리적으로 메모리에서 불필요한 페이지를 보조기억장치로 내보낼 수 있어야 한다.

### 요구 페이징

- 프로세스를 메모리에 적재할 때, 처음부터 모든 페이지를 적재하지 않고 필요한 페이지만을 적재하는 기법을 **요구 페이징**(Demand Paging)이라고 한다.
- 실행에 요구되는 페이지만 적재하는 기법이다.
- 요구 페이징의 기본적인 양상
  1. CPU가 특정 페이지에 접근하는 명령어를 실행한다.
  2. 해당 페이지가 현재 메모리에 있을 경우(유효 비트가 1인 경우) CPU는 페이지가 적재된 프레임에 접근한다.
  3. 해당 페이지가 현재 메모리에 없을 경우(유효 비트가 0인 경우) 페이지 폴트가 발생한다.
  4. 페이지 폴트 처리 루틴은 해당 페이지를 메모리로 적재하고 유효 비트를 1로 설정한다.
  5. 다시 1번을 수행한다.
- 참고로 아무런 페이지도 메모리에 적재하지 않은 채 무작정 실행부터 할 수도 있다. 이 경우 처음부터 페이지 폴트가 계속 발생하고, 어느정도 실행에 필요한 페이지가 적재된 이후부터는 페이지 폴트 발생 빈도가 떨어진다. 이를 **순수 요구 페이징 기법**이라고 한다.
- 요구 페이징 시스템이 안정적으로 작동하려면, 반드시 **페이지 교체**와 **프레임 할당**이 제대로 해결되어야 한다.
- 요구 페이징 기법으로 페이지들을 적재하다 보면 언젠가 메모리가 가득 차게 된다. 이 땐 필요한 페이지를 적재하기 위해 메모리에 적재된 페이지들을 보조기억장치로 내보내야 한다.
- 메모리에 적재된 많은 페이지들 중 어떤 것을 내보내는게 가장 최선일지 찾는 것이 **페이지 교체 알고리즘**이다.

### 페이지 교체 알고리즘

- 일반적으로 페이지 폴트를 가장 적게 일으키는 알고리즘을 좋은 알고리즘으로 평가한다.
- 가령 한 알고리즘을 통해 페이지를 스왑 아웃시켰을 때, 페이지 폴트가  자주 발생하면 이는 보조기억장치로 내쫓을 페이지를 잘못 골랐다는 뜻으로 이는 좋은 알고리즘이 아닌 것이다.
- 그렇기에 페이지 교체 알고리즘을 제대로 이해하려면 **페이지 폴트 횟수**를 알 수 있어야 한다.
- 그리고 페이지 폴트 횟수는 **페이지 참조열**을 통해 알 수 있다.
- 페이지 참조열은 CPU가 참조하는 페이지들 중 연속된 페이지를 생략한 페이지열을 의미한다.
- 연속된 페이지를 생략하는 이유는, 중복된 페이지를 참조하는 행위는 페이지 폴트를 발생시키지 않기 때문이다.
- **FIFO 페이지 교체 알고리즘**
  - 이는 가장 단순한 방법으로, 가장 먼저 메모리에 올라온 페이지부터 내쫓는 방식이다.
  - 아이디어와 구현이 간단하나 마냥 좋은 것은 아니다. 자주 참조되는 페이지가 먼저 적재되었다는 이유만으로 내쫓길 수도 있다.
  - 이를 어느정도 방지한 변형 알고리즘인 **2차 기회 페이지 교체 알고리즘**이 존재한다. FIFO와 똑같이 오래 머무른 페이지를 교체 대상으로 선별하나, 참조 비트가 1일 경우 당장 내쫓지 않고 참조 비트를 0으로 만든 뒤 현재 시간을 적재 시간으로 설정한다.
  - 오래 머무름과 동시에 참조 비트마저 0이라면 내쫓는 방식이다.
- **최적 페이지 교체 알고리즘**
  - CPU에 의해 참조되는 횟수를 고려하는 페이지 교체 알고리즘이다.
  - 앞으로의 사용 빈도가 가장 낮은 페이지를 교체하는 알고리즘이다.
  - 가장 낮은 페이지 폴트율을 보장하는 알고리즘이며, 여러 페이지 참조열을 가지고 실험해보면 다른 페이지 교체 알고리즘에 비해 페이지 폴트 발생 빈도가 가장 낮다.
  - 다만, **실제 구현이 어렵다.** 앞으로 오랫동안 사용되지 않을 페이지를 내보내는 알고리즘인데, 이를 예측하기가 어렵기 때문이다.
  - 그래서 이 알고리즘은 그 자체로 사용하기보단, 다른 페이지 교체 알고리즘의 이론상 성능을 평가할 때 자주 쓰인다. 특정 페이지 교체 알고리즘과 이 알고리즘간의 페이지 폴트 횟수 대결을 통해 얼마나 격차가 적은지 평가하기 위해 쓴다.
- **LRU 페이지 교체 알고리즘**
  - 최적 페이지 교체 알고리즘과 비슷한 알고리즘으로, 가장 오랫동안 사용되지 '않을'이 아닌, '않은' 페이지를 교체하는 알고리즘이다.
  - 최근에 사용되지 않은 페이지는 앞으로도 사용되지 않을 것이라는 아이디어를 토대로 만들어진 알고리즘이다.

### 스래싱과 프레임 할당

- 페이지 폴트의 발생 빈도엔 나쁜 페이지 교체 알고리즘뿐만이 원인이 아니다.
- 프로세스가 사용할 수 있는 프레임 수가 적어도 페이지 폴트는 자주 발생한다.
- 사실 이것이 더 근본적인 이유라고도 볼 수 있다.
- 공간이 적으면, 프레임의 수가 적으면 CPU는 페이지 폴트를 자주 발생시킬 테고, CPU가 뚝뚝 끊키며 이용률이 떨어지는데, 이는 생산성이 낮아지는 결과를 초래한다.
- 이처럼 프로세스가 실제 실행되는 시간보다 페이징에 더 많은 시간을 소요하여 성능이 저해되는 문제를 **스래싱**(Threashing)이라고 한다.
- 메모리에서 동시에 실행되는 프로세스의 수를 **멀티프로그래밍의 정도**라고 표현하는데, 멀티프로그래밍의 정도가 높을 수록 CPU 이용률이 저하되다가 급격하게 낮아지는 부분이 있으며, 그 구간이 스래싱이다.
- 스래싱이 발생하는 근본적인 원인은 각 프로세스가 필요로 하는 최소한의 프레임 수가 보장되지 않았기 때문이다.
- 실행에 최소한으로 필요한 프레임 수가 열 개인데, 다섯 개만 존재한다면 빈번한 페이지 폴트를 야기하고, 이는 스래싱으로 이어진다.
- 그래서 운영체제는 각 프로세스가 무리 없이 실행되기 위한 최소한의 프레임 수를 파악하고 적절하게 할당해야 한다.
- 가장 단순한 형태의 **프레임 할당 방식**은 모든 프로세스에 균등하게 프레임을 제공하는 방식이다. 프레임이 300개 있고, 프로세스가 3개 있다면 각각 100개씩 할당하는 방식이다. 이러한 프레임 할당 방식을 **균등 할당**이라고 한다.
- 그러나 이는 그리 권장하는 방식이 아니다. 실행되는 프로세스들의 크기는 천차만별이기 때문이다.
- 크기가 큰 프로세스에 프레임을 많이 할당하고, 크기가 작으면 프레임을 적게 나눠주는 방식을 **비례 할당**이라고 한다.
  - 균등 할당과 비례 할당은 프로세스 실행 과정보단 크기와 물리 메모리의 용량만 보고 결정하기에 **정적 할당 방식**이라고도 한다.
- 하지만 막상 프로세스의 크기가 커도 실행해보니 별로 많은 프레임을 필요로 하지 않는 경우도 존재한다. 그 반대의 예시도 존재한다. 즉, 하나의 프로세스가 얼마나 많은 프레임을 필요로 할지는 결국 실행해 봐야 아는 경우가 많다.
- 프로세스를 실행하는 과정에서 배분할 프레임을 결정하는 방식에는 크게 **작업 집합 모델**을 사용하는 방식과 **페이지 폴트 빈도**를 사용하는 방식이 있다.
  - 이 두 과정은 프로세스 실행을 보고 할당할 프레임 수를 정하기에 **동적 할당 방식**이라고도 한다.
- **작업 집합 모델 기반 프레임 할당**
  - 스래싱이 발생하는 이유는 빈번한 페이지 교체 때문이다.
  - 이 방식은 프로세스가 일정 기간 동안 참조한 페이지 집합을 기억하여, 빈번한 페이지 교체를 방지한다.
  - 참조 지역성의 원리에 의거해 CPU는 비교적 비슷한 구역을 집중적으로 참조하는데, 여러 페이지들 중에서도 집중적으로 참조하는 구간이 존재한다.
  - CPU가 특정 시간 동안 주로 참조한 페이지 개수만큼만 프레임을 할당하면 페이지 교체 횟수가 떨어질 것이다.
  - 실행 중인 프로세스가 일정 시간 동안 참조한 페이지의 집합을 **작업 집합**(Working Set)이라고 한다.
- **페이지 폴트 빈도 기반 프레임 할당**
  - 페이지 폴트율이 너무 높으면 그 프로세스는 너무 적은 프레임을 가지고 있다, 페이지 폴트율이 너무 낮으면 그 프로세스는 너무 많은 프레임을 가지고 있다는 생각을 토대로 생겨난 아이디어이다.
  - 페이지 폴트율과 할당된 프레임 수는 서로 반비례 관계이다.
  - 페이지 폴트율이 상한선보다 높아지면 더 프레임을 할당해주고, 페이지 폴트율이 하한선보다 낮아지면 프레임을 회수한다.